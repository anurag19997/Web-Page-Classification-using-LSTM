{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from random import shuffle\n",
    "import zipfile\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('processed_train_data.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage_id</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Url</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/marketing/tecfidera-gilenya-and-aubagio-s-3-way-battle-for-ms-share-about-to-get-more-interesting</td>\n",
       "      <td>news</td>\n",
       "      <td>Tecfidera, Gilenya and Aubagio&amp;#039;s 3-way battle for MS share is about to heat up | FiercePharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/novo-equipped-to-weather-storm-u-s-diabetes-market-ceo-says</td>\n",
       "      <td>news</td>\n",
       "      <td>Novo equipped to weather the storm in the U.S. diabetes market, CEO says | FiercePharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/another-exec-departs-troubled-endo-and-time-it-s-for-another-drugmaker</td>\n",
       "      <td>news</td>\n",
       "      <td>Another exec departs troubled Endo--and this time, it&amp;#039;s for another drugmaker | FiercePharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/pharma/teva-buy-biosim-specialist-celltrion-it-wouldn-t-say-no</td>\n",
       "      <td>news</td>\n",
       "      <td>Would Teva buy Korea&amp;#039;s Celltrion to beef up in biosimilars? It wouldn&amp;#039;t say no | FiercePharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>www.fiercepharma.com</td>\n",
       "      <td>http://www.fiercepharma.com/marketing/actress-marissa-tomei-partners-allergan-restasis-to-drive-dry-eye-awareness</td>\n",
       "      <td>news</td>\n",
       "      <td>Restasis-maker Allergan recruits actress Marisa Tomei to drive dry eye awareness | FiercePharma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Webpage_id                Domain  \\\n",
       "0  1          www.fiercepharma.com   \n",
       "1  2          www.fiercepharma.com   \n",
       "2  3          www.fiercepharma.com   \n",
       "3  4          www.fiercepharma.com   \n",
       "4  5          www.fiercepharma.com   \n",
       "\n",
       "                                                                                                                             Url  \\\n",
       "0  http://www.fiercepharma.com/marketing/tecfidera-gilenya-and-aubagio-s-3-way-battle-for-ms-share-about-to-get-more-interesting   \n",
       "1  http://www.fiercepharma.com/pharma/novo-equipped-to-weather-storm-u-s-diabetes-market-ceo-says                                  \n",
       "2  http://www.fiercepharma.com/pharma/another-exec-departs-troubled-endo-and-time-it-s-for-another-drugmaker                       \n",
       "3  http://www.fiercepharma.com/pharma/teva-buy-biosim-specialist-celltrion-it-wouldn-t-say-no                                      \n",
       "4  http://www.fiercepharma.com/marketing/actress-marissa-tomei-partners-allergan-restasis-to-drive-dry-eye-awareness               \n",
       "\n",
       "    Tag  \\\n",
       "0  news   \n",
       "1  news   \n",
       "2  news   \n",
       "3  news   \n",
       "4  news   \n",
       "\n",
       "                                                                                                      Html  \n",
       "0  Tecfidera, Gilenya and Aubagio&#039;s 3-way battle for MS share is about to heat up | FiercePharma       \n",
       "1  Novo equipped to weather the storm in the U.S. diabetes market, CEO says | FiercePharma                  \n",
       "2  Another exec departs troubled Endo--and this time, it&#039;s for another drugmaker | FiercePharma        \n",
       "3  Would Teva buy Korea&#039;s Celltrion to beef up in biosimilars? It wouldn&#039;t say no | FiercePharma  \n",
       "4  Restasis-maker Allergan recruits actress Marisa Tomei to drive dry eye awareness | FiercePharma          "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53447 entries, 0 to 53558\n",
      "Data columns (total 5 columns):\n",
      "Webpage_id    53447 non-null object\n",
      "Domain        53447 non-null object\n",
      "Url           53447 non-null object\n",
      "Tag           53447 non-null object\n",
      "Html          53447 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df.Tag.values\n",
    "df.dropna(axis=0,subset=['Tag'],inplace=True)\n",
    "df.Html.fillna(value='missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53447 entries, 0 to 53558\n",
      "Data columns (total 5 columns):\n",
      "Webpage_id    53447 non-null object\n",
      "Domain        53447 non-null object\n",
      "Url           53447 non-null object\n",
      "Tag           53447 non-null object\n",
      "Html          53447 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(url,title):\n",
    "    \n",
    "    pattern=r'//.*'\n",
    "    urls=[]\n",
    "    for i in url:\n",
    "        b=re.findall(pattern,i)\n",
    "        c=b[0][2:]\n",
    "        d=re.split('\\.|/|-|_',c)\n",
    "        e=''\n",
    "        for i in d:\n",
    "            e+=str(i).lower()\n",
    "            e+=' '\n",
    "        e = ''.join([i for i in e if not i.isdigit()])\n",
    "        f=''\n",
    "        for i in e:\n",
    "            if i.isalpha() or i==' ':\n",
    "                f+=i\n",
    "            else:\n",
    "                f+=' '\n",
    "        urls.append(f)\n",
    "        \n",
    "    titles=[]\n",
    "    for e in title:    \n",
    "        e = ''.join([i for i in e if not i.isdigit()])\n",
    "        f=''\n",
    "        for i in e:\n",
    "            if i.isalpha() or i==' ':\n",
    "                #print(i)\n",
    "                f+=i\n",
    "            else:\n",
    "                f+=' '\n",
    "        f = re.sub(' +',' ',f) # replace series of spaces with single space\n",
    "        titles.append(f)\n",
    "    \n",
    "    data=[]\n",
    "    for i in range(len(title)):\n",
    "        s=titles[i]+' '+urls[i]\n",
    "        data.append(str(s))\n",
    "        \n",
    "    count_vect = CountVectorizer()\n",
    "    X_train_counts = count_vect.fit_transform(urls)\n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "urls=preprocess(df.Url,df.Html)\n",
    "#target=df.Tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53447 entries, 0 to 53558\n",
      "Data columns (total 5 columns):\n",
      "Webpage_id    53447 non-null object\n",
      "Domain        53447 non-null object\n",
      "Url           53447 non-null object\n",
      "Tag           53447 non-null object\n",
      "Html          53447 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tecfidera Gilenya and Aubagio s way battle for MS share is about to heat up FiercePharma www fiercepharma com marketing tecfidera gilenya and aubagio s  way battle for ms share about to get more interesting ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['news', 'news', 'news', 'news', 'news'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishant\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8843527232585552"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=0.001, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(urls, target)\n",
    "predicted_svm = text_clf_svm.predict(urls)\n",
    "np.mean(predicted_svm == target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishant\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9585757853574569"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(urls)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    \n",
    "svm=SGDClassifier(loss='hinge', penalty='l2',alpha=0.001, n_iter=5, random_state=42)\n",
    "\n",
    "svm.fit(X_train_counts,target)\n",
    "predicted= svm.predict(X_train_counts)\n",
    "np.mean(predicted==target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46298"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53447,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X_train_tfidf,target,i,batch_size):\n",
    "    batch_data = X_train_tfidf[i*batch_size:i*batch_size+batch_size]\n",
    "    batch_target = target[i*batch_size:i*batch_size+batch_size]\n",
    "    \n",
    "    return(np.array(batch_data),np.array(batch_target))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "epochs=5\n",
    "batch_size=100\n",
    "\n",
    "input_size=X_train_tfidf.shape[1]\n",
    "hidden_size=100\n",
    "output_size=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.layer1=nn.Linear(input_size,hidden_size,bias=True)\n",
    "        self.relu=nn.ReLU()\n",
    "        #self.layer2=nn.Linear(hidden_size,hidden_size,bias=True)\n",
    "        self.output_layer=nn.Linear(hidden_size,output_size,bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.output_layer(out)\n",
    "        return(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MyNet(input_size,hidden_size,output_size)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m)\n * (tuple of ints size, torch.device device)\n * (Tensor indices, Tensor values, torch.device device)\n * (Tensor indices, Tensor values, tuple of ints size, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-2c13d7c184d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;31m#torch.sparse.FloatTensor(indices, values, size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m)\n * (tuple of ints size, torch.device device)\n * (Tensor indices, Tensor values, torch.device device)\n * (Tensor indices, Tensor values, tuple of ints size, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_batch=int(X_train_tfidf.shape[0]/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_data,batch_target=get_batch(X_train_tfidf,target,i,batch_size)\n",
    "        text=Variable(torch.sparse.FloatTensor(batch_data))\n",
    "        #torch.sparse.FloatTensor(indices, values, size)\n",
    "        tag=Variable(torch.sparse.FloatTensor(batch_target))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=net.forward(text)\n",
    "        loss=criterion(output,tag)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(loss.data[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: double, float, float16, int64, int32, and uint8.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-13f6d30f220a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: double, float, float16, int64, int32, and uint8."
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "batch_data,batch_target=get_batch(X_train_counts,target,0,batch_size)\n",
    "text=Variable(torch.FloatTensor(batch_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-5abdec752fde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m    182\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             raise ValueError(\"The truth value of an array with more than one \"\n\u001b[0m\u001b[0;32m    259\u001b[0m                              \"element is ambiguous. Use a.any() or a.all().\")\n\u001b[0;32m    260\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "a=coo_matrix(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<53447x46298 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 720665 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X_train_counts[:1000].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 46298)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "S = csr_matrix(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=S[:100].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720665,)\n"
     ]
    }
   ],
   "source": [
    "#print(S.data.shape)   #values \n",
    "#print(S.indices.shape)       #y coordinate  \n",
    "print(S.getcol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 46298)\n"
     ]
    }
   ],
   "source": [
    "print(S[:2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 3)\t2\n",
      "[[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 0, 0, 1, 0, 0], [0, 0, 2, 0, 0, 1], [0, 0, 0, 2, 0, 0]])\n",
    "print(A)\n",
    "# convert to sparse matrix (CSR method)\n",
    "S = csr_matrix(A)\n",
    "print(S)\n",
    "# reconstruct dense matrix\n",
    "B = S.todense()\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
